curl -sS https://raw.githubusercontent.com/albertoclarit/DevOps/master/settingk8.sh | bash


 ####  replace apiserver-advertise-address ####
kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=10.132.72.132 --kubernetes-version stable-1.9 --ignore-preflight-errors=cri

 ### watch the join token ####

kubeadm join --token cc1175.8bc6d97ce926a20a 10.132.72.132:6443 --discovery-token-ca-cert-hash sha256:d7df01464da6758805d7694053b81f9ffcdb25d53bf0935909d3026c26ae0044

 ### watch the join token ####


adduser master
usermod -aG sudo master

su master

curl -sS https://raw.githubusercontent.com/albertoclarit/DevOps/master/setupenv.sh | bash


 install flannel

 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/k8s-manifests/kube-flannel-rbac.yml

 kubectl get all --namespace=kube-system

 install ingressnginx.txt


 curl https://raw.githubusercontent.com/albertoclarit/DevOps/master/fabric8cluster.yml \
     | kubectl apply -f -



##### Teardown #####
To undo what kubeadm did, you should first drain the node and make sure that the node is empty before shutting it down.
Talking to the master with the appropriate credentials, run:


kubectl drain <node name> --delete-local-data --force --ignore-daemonsets
kubectl delete node <node name>

kubeadm reset
