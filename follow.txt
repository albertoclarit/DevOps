
https://askubuntu.com/questions/162391/how-do-i-fix-my-locale-issue

journalctl -u nginx.service

Check if  VXLAN is supported
curl -sSL https://raw.githubusercontent.com/docker/docker/master/contrib/check-config.sh | bash

If you are using Kubernetes 1.7+ then the following applies:
* Swap must be disabled
You can check if you have swap enabled by typing in cat /proc/swaps. If you have a swap file or partition enabled then turn it off with swapoff. You can make this permanent by commenting out the swap file in /etc/fstab.



curl -sS https://raw.githubusercontent.com/albertoclarit/DevOps/master/settingk8.sh | bash


 ####  replace apiserver-advertise-address ####
kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address=192.168.1.149 --kubernetes-version stable-1.9 --ignore-preflight-errors=cri

 ### watch the join token ####

kubeadm join --token d9c7f4.77c2d5a44526aab1 192.168.1.149:6443 --discovery-token-ca-cert-hash sha256:40f55e0c71cec177213f7e3dee397f4d916243346e716fb52dc1c6d36255574c  --ignore-preflight-errors=cri
 ### watch the join token ####


adduser master
usermod -aG sudo master

su master

curl -sS https://raw.githubusercontent.com/albertoclarit/DevOps/master/setupenv.sh | bash

 kubectl taint nodes --all node-role.kubernetes.io/master-

 install flannel from official
 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml


 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
 kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/k8s-manifests/kube-flannel-rbac.yml

 kubectl get all --namespace=kube-system


### without flannel dns pod will not start
  kubectl describe pod -n namespace  namepod
  kubectl describe node namenode


 install ingressnginx.txt

 ### if pending ####
 kubectl delete --all deployment --namespace=ingress-nginx



 curl https://raw.githubusercontent.com/albertoclarit/DevOps/master/fabric8cluster.yml \
     | kubectl apply -f -

 watch kubectl get pods --all-namespaces
 watch kubectl get pods --all-namespaces -o wide



https://help.ubuntu.com/lts/serverguide/network-file-system.html
https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-16-04
https://askubuntu.com/questions/525243/why-do-i-get-wrong-fs-type-bad-option-bad-superblock-error
https://kubernetes.io/docs/concepts/storage/persistent-volumes/#recycling
https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
https://kubernetes.io/docs/tasks/debug-application-cluster/get-shell-running-container/

- get original yaml
kubectl get pvc -n fabric8 fabric8-docker-registry-storage  --export=true -o yaml


-- if using gofabric deploy
 curl https://raw.githubusercontent.com/albertoclarit/DevOps/master/pvcfabricfinal.yml \
     | kubectl apply -f -





In the past, the annotation volume.beta.kubernetes.io/storage-class was used
instead of the storageClassName attribute. This annotation is still working,
however it will become fully deprecated in a future Kubernetes release.
https://kubernetes.io/docs/concepts/storage/persistent-volumes/#class


https://github.com/fabric8io/gofabric8/issues/619#issuecomment-349726104
https://stackoverflow.com/questions/44204223/kubernetes-nfs-persistent-volumes-multiple-claims-on-same-volume-claim-stuck
you cannot bound multiple pvc to a single pv


-- patching resource
kubectl patch pvc wit-postgresql-data  -p '{"spec":{"storageClassName":"standard"}}'



 Try Using Helm
Using Helm
https://docs.helm.sh/using_helm/#installing-helm
https://stackoverflow.com/questions/43499971/helm-error-no-available-release-name-found


using helm
curl https://raw.githubusercontent.com/albertoclarit/DevOps/master/pvcfabric.yml \
          | kubectl apply -f -

install first in help


curl https://raw.githubusercontent.com/albertoclarit/DevOps/master/ingress_expose.yml \
          | kubectl apply -f -

     Installing Fabric8

     export GITHUB_OAUTH_CLIENT_ID=123
     export GITHUB_OAUTH_CLIENT_SECRET=123abc
     export TLS_ACME_EMAIL=albertoclarit@gmail.com@for.certbot.com

     curl -sS https://get.fabric8.io/download.txt | bash

     gofabric8 deploy —-ingress=false --package system --http=true  --domain 159.89.201.44.nip.io --legacy=false -n fabric8
     gofabric8 deploy —-ingress=false --package system --http=true  --domain 159.89.201.44.nip.io --legacy=false

      gofabric8 deploy  --http=true  --domain 159.89.201.44.nip.io


     gofabric8 secrets -y

     kubectl exec -t -i guids-2617315942-lzwdh sh

     gofabric8 clean system
     gofabric8 clean apps

gofabric8 validate
gofabric8 service fabric8 --url
gofabric8 service gogs
gofabric8 service jenkins
gofabric8 service nexus


not used anymore
curl https://raw.githubusercontent.com/albertoclarit/DevOps/master/exposefabricpublic.yml \
          | kubectl apply -f -



kubectl get ing


https://kubernetes.io/docs/tutorials/stateless-application/expose-external-ip-address/
https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-controllers
https://blog.fabric8.io/accessing-your-applications-on-kubernetes-or-openshift-3e69be0ad3bc

##### Teardown #####
To undo what kubeadm did, you should first drain the node and make sure that the node is empty before shutting it down.
Talking to the master with the appropriate credentials, run:


kubectl drain node1 --delete-local-data --force --ignore-daemonsets
kubectl delete node node1

kubectl drain master --delete-local-data --force --ignore-daemonsets
kubectl delete node master

kubeadm reset
